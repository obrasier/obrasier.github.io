{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay we've downloaded the files we need from [this dataset](https://www.kaggle.com/cclayford/cricinfo-statsguru-data/data). I just run these bash commands to rename the files for easier shell handling <br> \n",
    "\n",
    "find *.csv -exec rename 's/\\s/_/g' {} \\;\n",
    "\n",
    "Then to make all the files lowercase:\n",
    "find *.csv -exec rename 'y/A-Z/a-z/' {} \\;\n",
    "\n",
    "To fix up the headings, we do the same for the first line in all the csv files.\n",
    "\n",
    "1s/.*/\\L&/ < on the first line, make sure all characters are lowercase \\L\n",
    "1s/ /_/g ... on the first line, replace all spaces with underscores, globally\n",
    "\n",
    "find *.csv -exec sed -i '1s/.*/\\L&/;1s/ /_&/' {} \\;\n",
    "\n",
    "Okay that's it. We've done the file processing, now to load them all into jupyter. \n",
    "\n",
    "I'm just going to be looking at the Men's test individual data. But you could do the same for the women, ODIs, etc. Just load those into the dataframe instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob('data/men_test_player_innings_stats_-_*.csv')\n",
    "\n",
    "# low_memory=False just tries to figure out the data type of large files.\n",
    "# we don't really need this, because we'll fix these later.\n",
    "df = pd.concat((pd.read_csv(f, low_memory=False) for f in all_files))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a few things we should do before we can start processing the data.\n",
    "- drop the duplicate rows\n",
    "- change the type of data to the appropriate data type in each column (I *definitely* knew about this before starting the post, yep, *definitely*)\n",
    "- Sort by date - which will be a handy default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "\n",
    "int_cols = ['innings_runs_scored_num', 'innings_minutes_batted', \n",
    "            'innings_batted_flag', 'innings_not_out_flag', 'innings_bowled_flag',\n",
    "            'innings_balls_faced', 'innings_boundary_fours',\n",
    "            'innings_boundary_sixes', 'innings_maidens_bowled',\n",
    "            'innings_runs_conceded', 'innings_wickets_taken',\n",
    "            '4_wickets', '5_wickets', '10_wickets'\n",
    "           ]\n",
    "\n",
    "for col in int_cols:\n",
    "    # use to_numeric to convery the - to NaN (not-a-number)\n",
    "    # \"Int32\" has mixed NaNs and integers\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').astype(\"Int32\")\n",
    "    \n",
    "\n",
    "df.innings_economy_rate = pd.to_numeric(df.innings_economy_rate, errors='coerce')\n",
    "df.innings_date = pd.to_datetime(df.innings_date, infer_datetime_format=True)\n",
    "df = df.sort_values(by=['innings_date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now we've gotten to the point where we hoped we would have started, clean data, I guess. How do we know we haven't fucked something up? \n",
    "\n",
    "Well, Don Bradman's test batting average was 99.94, famously, how about we write a function to check the average is correct. \n",
    "\n",
    "SQL is feeling a little bit lame, honestly, so how about we stick to what we know and write a function to get the average.\n",
    "\n",
    "Ao the average of a batter is the number of runs scored in their career minus the number of times they have been dismissed.\n",
    "\n",
    "So we can write a function for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.94285714285714\n"
     ]
    }
   ],
   "source": [
    "def get_total_runs(player):\n",
    "    return df.loc[df['innings_player'] == player, 'innings_runs_scored_num'].sum()\n",
    "\n",
    "def times_dismissed(player):\n",
    "    num_innings = len(df.loc[df['innings_player'] == player, 'innings_runs_scored_num'].dropna())\n",
    "    not_out = df.loc[df['innings_player'] == player, 'innings_not_out_flag'].sum()\n",
    "    return num_innings - not_out\n",
    "\n",
    "def get_average(player):\n",
    "    runs = get_total_runs(player)\n",
    "    dismissed = times_dismissed(player)\n",
    "    if dismissed == 0:\n",
    "        return np.nan\n",
    "    return runs / dismissed\n",
    "print(get_average('DG Bradman'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuckn yeh boooooiiiii!\n",
    "\n",
    "That was fun an all, but really, what we want is to do some fucking number crunching here. We can calculate the average of every player in the history of the game.\n",
    "\n",
    "First we want to get all the players..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      innings_player     average\n",
      "22755   KR Patterson  144.000000\n",
      "66931   AG Ganteaume  112.000000\n",
      "48719       Abid Ali  107.000000\n",
      "50574     DG Bradman   99.942857\n",
      "62077       MN Nawaz   99.000000\n",
      "60884  VH Stollmeyer   96.000000\n",
      "85275       DM Lewis   86.333333\n",
      "69175     Abul Hasan   82.500000\n",
      "91237     RE Redmond   81.500000\n",
      "30714    DJ Mitchell   73.000000\n"
     ]
    }
   ],
   "source": [
    "all_players = pd.DataFrame(df.innings_player.drop_duplicates())\n",
    "\n",
    "averages = all_players # make a copy because we'll use all_players a lot later.\n",
    "averages['average'] = averages.innings_player.apply(get_average)\n",
    "\n",
    "# filter out infinite and not-a-number results\n",
    "averages.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "averages.dropna(inplace=True)\n",
    "averages.sort_values(by=['average'], ascending=False, inplace=True)\n",
    "print(averages[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the fuck! That can't be real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Don got 7 ducks\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_all_player_stats(player):\n",
    "    # return the entire dataframe but filtered for that player\n",
    "    return df.loc[df['innings_player'] == player]\n",
    "\n",
    "def num_ducks(player):\n",
    "    all_stats = get_all_player_stats(player)\n",
    "    ducks = all_stats[(all_stats.innings_not_out_flag == 0) & (all_stats.innings_runs_scored_num == 0)]\n",
    "    return len(ducks)\n",
    "print(f\"The Don got {num_ducks('DG Bradman')} ducks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.options.mode.chained_assignment = None\n",
    "\n",
    "def get_all_player_stats(player, data):\n",
    "    # return the entire dataframe but filtered for that player\n",
    "    return data[data['innings_player'] == player]\n",
    "\n",
    "def get_all_teams_stats(team, data):\n",
    "    return data[data['team'] == team]\n",
    "    \n",
    "\n",
    "def num_matches(test, col, test_num, df_data, greater, individual=True):\n",
    "    # https://stackoverflow.com/questions/40068261/pandas-dataframe-find-longest-consecutive-rows-with-a-certain-condition\n",
    "    # Special mention to the above post for this solution.\n",
    "    data = df_data.copy()\n",
    "    data = data[data[col] != np.nan]\n",
    "    if greater:\n",
    "        data['condition_true'] = np.where(data[col] > test_num, True, False)\n",
    "    else:\n",
    "        data['condition_true'] = np.where(data[col] < test_num, True, False)\n",
    "    if individual:\n",
    "        all_stats = get_all_player_stats(test, data)\n",
    "    else:\n",
    "        all_stats = get_all_teams_stats(test, data)\n",
    "    df_bool = all_stats['condition_true'] != all_stats['condition_true'].shift()\n",
    "    df_cumsum = df_bool.cumsum()\n",
    "    groups = all_stats.groupby(df_cumsum)\n",
    "    group_counts = groups.agg({col: ['count', 'min', 'max']})\n",
    "    group_counts.columns = group_counts.columns.droplevel()\n",
    "    if greater:\n",
    "        group_counts = group_counts[group_counts['min'] > test_num]\n",
    "    else:\n",
    "        group_counts = group_counts[group_counts['max'] < test_num]\n",
    "    max_count = group_counts['count'].max()\n",
    "    return max_count\n",
    "\n",
    "def num_matches_group(test, col, test_num, df_data, greater, individual=True):\n",
    "    # https://stackoverflow.com/questions/40068261/pandas-dataframe-find-longest-consecutive-rows-with-a-certain-condition\n",
    "    # Special mention to the above post for this solution.\n",
    "    data = df_data.copy()\n",
    "    data = data[data[col] != np.nan]\n",
    "    if greater:\n",
    "        data['condition_true'] = np.where(data[col] > test_num, True, False)\n",
    "    else:\n",
    "        data['condition_true'] = np.where(data[col] < test_num, True, False)\n",
    "#     print(data)\n",
    "    if individual:\n",
    "        all_stats = get_all_player_stats(test, data)\n",
    "    else:\n",
    "        all_stats = get_all_teams_stats(test, data)\n",
    "    df_bool = all_stats['condition_true'] != all_stats['condition_true'].shift()\n",
    "    df_cumsum = df_bool.cumsum()\n",
    "    groups = all_stats.groupby(df_cumsum)\n",
    "    \n",
    "    # this is the worst code I've ever written.\n",
    "    # please don't judge, it's 1am and I got it to work.\n",
    "    # I'm sure groupby has a thing that does this, but I am too tired to figure it out.\n",
    "    max_len = 0\n",
    "    resulting_df = None\n",
    "    for g in groups:\n",
    "        if g[1].condition_true.all() == True:\n",
    "            if len(g[1]) > max_len:\n",
    "                max_len = len(g[1])\n",
    "                resulting_df = g[1]\n",
    "    return max_len, resulting_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      innings_player    average  greater_40\n",
      "28904      JH Kallis  55.255230        10.0\n",
      "84190      ED Weekes  58.618421         9.0\n",
      "99630  Javed Miandad  52.571429         8.0\n",
      "19156       SR Waugh  51.060748         8.0\n",
      "57567      EJ Barlow  45.745455         8.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enter these values to match a condition\n",
    "match_name = 'greater_40'\n",
    "column = 'innings_runs_scored_num'\n",
    "greater_than = True\n",
    "condition_number = 40\n",
    "\n",
    "# comment out one of these lines to match the dataset you want\n",
    "match_data = df.copy()\n",
    "# match_data = team_innings.copy()\n",
    "\n",
    "\n",
    "all_players['greater_40'] = all_players.innings_player.apply(\n",
    "    num_matches, \n",
    "    args=(column, condition_number, match_data, greater_than))\n",
    "all_players.sort_values(by=['greater_40'], ascending=False, inplace=True)\n",
    "print(all_players[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      innings_player innings_runs_scored     opposition        ground  \\\n",
      "10166      JH Kallis                  43     v Pakistan    Faisalabad   \n",
      "10151      JH Kallis                  44  v West Indies  Johannesburg   \n",
      "9476       JH Kallis                 158  v West Indies  Johannesburg   \n",
      "9459       JH Kallis                 177  v West Indies        Durban   \n",
      "9536       JH Kallis                130*  v West Indies     Cape Town   \n",
      "9784       JH Kallis                  73  v West Indies     Cape Town   \n",
      "9537       JH Kallis                130*  v West Indies     Centurion   \n",
      "9489       JH Kallis                150*  v New Zealand      Hamilton   \n",
      "9679       JH Kallis                  92  v New Zealand      Hamilton   \n",
      "9798       JH Kallis                  71  v New Zealand      Auckland   \n",
      "\n",
      "      innings_date  innings_minutes_batted  innings_balls_faced  \\\n",
      "10166   2003-10-24                     174                  113   \n",
      "10151   2003-12-12                      96                   72   \n",
      "9476    2003-12-12                     411                  297   \n",
      "9459    2003-12-26                     479                  344   \n",
      "9536    2004-01-02                     262                  191   \n",
      "9784    2004-01-02                     207                  145   \n",
      "9537    2004-01-16                     247                  199   \n",
      "9489    2004-03-10                     406                  312   \n",
      "9679    2004-03-10                     239                  177   \n",
      "9798    2004-03-18                     165                  127   \n",
      "\n",
      "       innings_boundary_fours  innings_boundary_sixes  \\\n",
      "10166                       3                       0   \n",
      "10151                       3                       1   \n",
      "9476                       17                       1   \n",
      "9459                       20                       0   \n",
      "9536                        7                       5   \n",
      "9784                       13                       0   \n",
      "9537                       14                       1   \n",
      "9489                       19                       0   \n",
      "9679                       11                       3   \n",
      "9798                       11                       1   \n",
      "\n",
      "      innings_batting_strike_rate innings_number  \n",
      "10166                       38.05              3  \n",
      "10151                       61.11              3  \n",
      "9476                        53.19              1  \n",
      "9459                        51.45              2  \n",
      "9536                        68.06              3  \n",
      "9784                        50.34              1  \n",
      "9537                        65.32              1  \n",
      "9489                        48.07              3  \n",
      "9679                        51.97              1  \n",
      "9798                        55.90              3  \n"
     ]
    }
   ],
   "source": [
    "top_player = all_players.iloc[0,0]\n",
    "\n",
    "num, scores = num_matches_group(top_player, column, condition_number, df, greater_than, True)\n",
    "\n",
    "cols_to_print = ['innings_player', 'innings_runs_scored', 'opposition' ,'ground', 'innings_date', \n",
    "                 'innings_minutes_batted', 'innings_balls_faced', 'innings_boundary_fours',\n",
    "                 'innings_boundary_sixes','innings_batting_strike_rate', 'innings_number']\n",
    "print(scores[cols_to_print])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that lets us get all the innings that match. It's horrible code, I know, there has to be something that does it in one line. But I want to get this out the door working, and fix the computer-science-nerd-wank later.\n",
    "\n",
    "Jacques Kallis is a boss, it turns out, 10 innings in a row greater than 40. What a boss.\n",
    "\n",
    "\n",
    "So what if we wanted to perform the same action for a team innings. Well, the data we downloaded did not have all the indvidual team innings, unfortunately. But the data does exist on statsguru. So, I've modified a scraper that I found online to download the data. You can check out the [repo here](https://github.com/obrasier/statsguru-scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia\n",
      "21\n",
      "          team score  overs opposition      ground start_date\n",
      "80   Australia   123  118.3  v England  Manchester 1886-07-05\n",
      "83   Australia   121   82.3  v England      Lord's 1886-07-19\n",
      "84   Australia   126  111.1  v England      Lord's 1886-07-19\n",
      "86   Australia    68   60.2  v England    The Oval 1886-08-12\n",
      "87   Australia   149   97.0  v England    The Oval 1886-08-12\n",
      "89   Australia   119  113.1  v England      Sydney 1887-01-28\n",
      "91   Australia    97  107.0  v England      Sydney 1887-01-28\n",
      "93   Australia    84   55.1  v England      Sydney 1887-02-25\n",
      "95   Australia   150  110.0  v England      Sydney 1887-02-25\n",
      "97   Australia    42   37.3  v England      Sydney 1888-02-10\n",
      "99   Australia    82   69.2  v England      Sydney 1888-02-10\n",
      "100  Australia   116   71.2  v England      Lord's 1888-07-16\n",
      "102  Australia    60   29.2  v England      Lord's 1888-07-16\n",
      "104  Australia    80   90.3  v England    The Oval 1888-08-13\n",
      "106  Australia   100   69.2  v England    The Oval 1888-08-13\n",
      "108  Australia    81   52.2  v England  Manchester 1888-08-30\n",
      "109  Australia    70   31.1  v England  Manchester 1888-08-30\n",
      "117  Australia   132   86.0  v England      Lord's 1890-07-21\n",
      "119  Australia   176  140.2  v England      Lord's 1890-07-21\n",
      "121  Australia    92   65.2  v England    The Oval 1890-08-11\n",
      "123  Australia   102   60.2  v England    The Oval 1890-08-11\n"
     ]
    }
   ],
   "source": [
    "all_innings_file = 'data/all_test_innings.csv'\n",
    "all_innings = pd.read_csv(all_innings_file)\n",
    "all_innings.start_date = pd.to_datetime(all_innings.start_date, infer_datetime_format=True)\n",
    "all_innings.runs = pd.to_numeric(all_innings.runs, errors='coerce').astype(\"Int64\")\n",
    "\n",
    "all_teams = pd.DataFrame(all_innings.team.drop_duplicates())\n",
    "\n",
    "\n",
    "# Enter these values to match a condition\n",
    "match_name = 'under_200'\n",
    "column = 'runs'\n",
    "greater_than = False\n",
    "condition_number = 200\n",
    "\n",
    "# comment out one of these lines to match the dataset you want\n",
    "# match_data = df.copy()\n",
    "match_data = all_innings.copy()\n",
    "\n",
    "# all_players['greater_40'] = all_players.innings_player.apply(\n",
    "#     num_matches, \n",
    "#     args=(column, condition_number, all_innings, greater_than))\n",
    "# all_players.sort_values(by=['greater_40'], ascending=False, inplace=True)\n",
    "# print(all_players[:5])\n",
    "\n",
    "\n",
    "all_teams[match_name] = all_teams.team.apply(\n",
    "    num_matches, \n",
    "    args=(column, condition_number, all_innings, greater_than, False))\n",
    "all_teams.sort_values(by=[match_name], ascending=False, inplace=True)\n",
    "\n",
    "worst_team = all_teams.iloc[0,0]\n",
    "print(worst_team)\n",
    "\n",
    "amount, condition_innings = num_matches_group('Australia', 'runs', 200, all_innings, False, False)\n",
    "\n",
    "columns_to_print = ['team', 'score', 'overs', 'opposition', 'ground', 'start_date']\n",
    "print(amount)\n",
    "print(condition_innings[columns_to_print])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so we got what we were after, but we want more! Like a dog who wants a bone, we can never get enough stats. 21 scores under 200 in a row! When the hell were they! The last piece of our puzzle is to get the rows that match, and give us back the original dataframe so we can see where Australia's terrible streak was. Let me tell you now, this is a hard problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it works! We answered the queries, but it's a bit bloody clunky. I'm going to just submit this post now, but I will edit it. Because I'm sure I should have been using [df.query](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) this whole time to make it easier to write generic queries instead of the filtering I've been doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
